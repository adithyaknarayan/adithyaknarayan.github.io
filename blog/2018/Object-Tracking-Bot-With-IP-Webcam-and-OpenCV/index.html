<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Object Tracking Bot With IP Webcam and OpenCV | Adithya Narayan </title> <meta name="author" content="Adithya Narayan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adithyaknarayan.github.io/blog/2018/Object-Tracking-Bot-With-IP-Webcam-and-OpenCV/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Adithya</span> Narayan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Object Tracking Bot With IP Webcam and OpenCV</h1> <p class="post-meta"> January 01, 2018 </p> <p class="post-tags"> <a href="/blog/2018"> <i class="fa-solid fa-calendar fa-sm"></i> 2018 </a>   ·   <a href="/blog/tag/opencv"> <i class="fa-solid fa-hashtag fa-sm"></i> opencv</a>   <a href="/blog/tag/numpy"> <i class="fa-solid fa-hashtag fa-sm"></i> numpy</a>     ·   <a href="/blog/category/computer-vision"> <i class="fa-solid fa-tag fa-sm"></i> Computer Vision</a>   <a href="/blog/category/opencv"> <i class="fa-solid fa-tag fa-sm"></i> OpenCV</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>So, recently, I’ve been working on a 4-wheeled bot capable following a uniformly colored, regular object. Given that I’m still trying to figure out the nature of this blog, I’ve decided to go ahead and summarize the process of me trying to build this.  For the purpose of clarity, I’ve split the post into the three larger domains of work. Also, you can find the entire work on my github page.</p> <h1 id="tracking">Tracking</h1> <p>To begin with, I needed some way to send video data of what the bot was seeing to the computer so that it could be processed using OpenCV. Given that I didn’t have any small camera lying around, I decided to use my phone. In particular, there’s a pretty convenient Android application called “IP Webcam” with which you can stream video to a local IP address. It also has pretty nifty additional features like remotely turning on your phone camera’s light, enabling night vision, motion detection, etc.</p> <p>For this particular project I’ve used a form of colour tracking to track the object in the frame. To do this, I first stored each frame of the video stream in a variable called ‘cap’.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span> <span class="k">as</span> <span class="n">cv</span> 
<span class="n">cap</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nc">VideoCapture</span><span class="p">(</span><span class="sh">'</span><span class="s">enter the url here</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Then, using the functions ‘GaussianBlur’ and ‘cvtColor’ the frames were blurred and converted from the BRG scale to the HSV scale. Additionally, ‘inRange’ was used to isolate the colour blue from the frames.Subsequently, the images were eroded and dilated using in-built function available in OpenCV-Python. In general, this makes it easier to process the edges and also reduces the overall noise in each frame.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">blurred_frame</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nc">GaussianBlur</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">inRange</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">lower_val</span><span class="p">,</span><span class="n">upper_val</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">erode</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">dilate</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span><span class="n">iterations</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div> <p>With all of this done, we obtain a thresholded image where the colour blue has been isolated. However, this is not enough. For the robot to be able to follow the coloured object, the edges as well as the center of the object need to be identified. To do this, contours are used. By using the function ‘findContours’, a curve joining all continuous points on the thresholded frame is drawn. Additionally, ‘moments’ is used to find its center.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">channels</span> <span class="o">=</span> <span class="n">frame</span><span class="p">.</span><span class="n">shape</span>
<span class="n">iX</span> <span class="o">=</span> <span class="n">width</span><span class="o">/</span><span class="mi">2</span>
<span class="n">iY</span> <span class="o">=</span> <span class="n">height</span><span class="o">/</span><span class="mi">2</span>
 <span class="n">_</span><span class="p">,</span><span class="n">contours</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">findContours</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span><span class="n">cv</span><span class="p">.</span><span class="n">RETR_TREE</span><span class="p">,</span><span class="n">cv</span><span class="p">.</span><span class="n">CHAIN_APPROX_SIMPLE</span><span class="p">)</span>
<span class="k">if</span> <span class="n">cv</span><span class="p">.</span><span class="nf">contourArea</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
       <span class="n">M</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">moments</span><span class="p">(</span><span class="n">c</span><span class="p">);</span>
       <span class="n">cX</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">M</span><span class="p">[</span><span class="sh">"</span><span class="s">m10</span><span class="sh">"</span><span class="p">]</span><span class="o">/</span><span class="n">M</span><span class="p">[</span><span class="sh">"</span><span class="s">m00</span><span class="sh">"</span><span class="p">])</span>
       <span class="n">cY</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">M</span><span class="p">[</span><span class="sh">"</span><span class="s">m01</span><span class="sh">"</span><span class="p">]</span><span class="o">/</span><span class="n">M</span><span class="p">[</span><span class="sh">"</span><span class="s">m00</span><span class="sh">"</span><span class="p">])</span>
       <span class="n">cv</span><span class="p">.</span><span class="nf">drawContours</span><span class="p">(</span><span class="n">frame</span><span class="p">,[</span><span class="n">c</span><span class="p">],</span><span class="o">-</span><span class="mi">1</span><span class="p">,(</span><span class="mi">0</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
       <span class="n">cv</span><span class="p">.</span><span class="nf">circle</span><span class="p">(</span><span class="n">frame</span><span class="p">,(</span><span class="n">cX</span><span class="p">,</span><span class="n">cY</span><span class="p">),</span><span class="mi">7</span><span class="p">,(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
       <span class="n">cv</span><span class="p">.</span><span class="nf">putText</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="sh">"</span><span class="s">center</span><span class="sh">"</span><span class="p">,</span> <span class="p">(</span><span class="n">cX</span> <span class="o">-</span> <span class="mi">20</span><span class="p">,</span> <span class="n">cY</span> <span class="o">-</span><span class="mi">20</span><span class="p">),</span><span class="n">cv</span><span class="p">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
       <span class="n">res</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="nf">bitwise_and</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span><span class="n">frame</span><span class="p">,</span><span class="n">mask</span> <span class="o">=</span><span class="n">mask</span><span class="p">)</span>
</code></pre></div></div> <p>As can be seen above, I’ve also saved the co-ordinates of the center of each frame. To explain why that’s been done, I have to explain first how I plan to track the object. Essentially, my plan was to treat the center of the image as the origin and find the position of $cX$ and $cY$ relative to this origin.</p> <p><img src="vector_diagram.png" alt="Vector Diagram Figure"> <em>Determining the position vector.</em></p> <p>On doing so, we obtain a vector $\vec{P}$ which points from $(iX, iY)$ to $(cX,cY)$</p> \[\begin{aligned} \vec{P} = \begin{pmatrix} cY-iY\\cX-iX \end{pmatrix} \end{aligned}\] <p>From the components of this vector, we can draw a conclusion on whether the bot should turn clockwise or counter-clockwise. If $cX-iX &gt; 0$, then the bot should turn clockwise whereas if $cX-iX &lt; 0$ the bot should turn counter clockwise. By doing so, the bot constantly tries to align the center of the object with the y-axis of the frame.</p> <p>For the time being, the bot is unable to determine the object’s distance from the camera. However, this can be implemented by determining some scale factor between image size as seen by the camera and that of the object in real life. Then, the distance can be approximated by calcuating the focal length of the camera.</p> <h1 id="bluetooth-connector">Bluetooth Connector</h1> <p>Now that the bot knows where the object is and how it should move to centralize the image, a method is required to send this information to the Arduino. For this, the HC-05 bluetooth module was used using the wiring configuration shown here.</p> <p>Linux natively has no method for serial communication using bluetooth. However, by downloading something like Blueman, which is what was used in this case, you can allow for serial communication. Similarly, modules may be downloaded for python which allows you to write code for the communication part.</p> <p>For starters, the ‘bluetooth’ module is imported and nearby bluetooth devices are scanned for. Once the device with the name HC-05 is found and connected to, communication can begin. Additionally, since this python module uses sockets for communication, a socket is set up using the RFCOMM protocol.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">target_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">HC-05</span><span class="sh">"</span>
<span class="n">target_address</span> <span class="o">=</span> <span class="bp">None</span>
<span class="n">sock</span> <span class="o">=</span> <span class="n">bluetooth</span><span class="p">.</span><span class="nc">BluetoothSocket</span><span class="p">(</span><span class="n">bluetooth</span><span class="p">.</span><span class="n">RFCOMM</span><span class="p">)</span>
<span class="n">port</span> <span class="o">=</span> <span class="mi">1</span>
 
<span class="k">print</span> <span class="sh">"</span><span class="s">Searching for the HC-05 module...</span><span class="sh">"</span>
<span class="n">nearby_devices</span> <span class="o">=</span> <span class="n">bluetooth</span><span class="p">.</span><span class="nf">discover_devices</span><span class="p">()</span>
 
<span class="k">for</span> <span class="n">baddr</span> <span class="ow">in</span> <span class="n">nearby_devices</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">target_name</span> <span class="o">==</span> <span class="n">bluetooth</span><span class="p">.</span><span class="nf">lookup_name</span><span class="p">(</span><span class="n">baddr</span><span class="p">):</span>
        <span class="n">target_address</span> <span class="o">=</span> <span class="n">baddr</span>
        <span class="k">break</span>
 
<span class="k">if</span> <span class="n">target_address</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
    <span class="k">print</span> <span class="sh">"</span><span class="s">Done!</span><span class="sh">"</span>
    <span class="k">print</span> <span class="sh">"</span><span class="s">HC-05 found at the address</span><span class="sh">"</span><span class="p">,</span><span class="n">target_address</span>
    <span class="n">ans</span> <span class="o">=</span> <span class="nf">raw_input</span><span class="p">(</span><span class="sh">"</span><span class="s">Would you like to connect to it?[y/n]</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ans</span> <span class="o">==</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span>
        <span class="n">sock</span><span class="p">.</span><span class="nf">connect</span><span class="p">((</span><span class="n">target_address</span><span class="p">,</span> <span class="n">port</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span> <span class="sh">"</span><span class="s">Terminating...</span><span class="sh">"</span>
        <span class="nf">exit</span><span class="p">()</span>
 
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span> <span class="sh">"</span><span class="s">No bluetooth device found nearby. Please try again later</span><span class="sh">"</span>
    <span class="nf">exit</span><span class="p">()</span>
</code></pre></div></div> <p>For the simplicity, numbers are sent through the port to the Arduino instead of characters. Additionally, a small clearance of 10 units has been implemented. This is because, if one were to set ‘0’ as the only point where the bot stops, the bot would jitter a lot when the center of the object tries to align with the axis of the frame.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dX</span> <span class="o">=</span> <span class="n">cX</span><span class="o">-</span><span class="n">iX</span>
<span class="n">dY</span> <span class="o">=</span> <span class="n">cY</span><span class="o">-</span><span class="n">iY</span>
 
<span class="k">if</span> <span class="n">dX</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
   <span class="c1">#'1' is to turn cloackwise
</span>   <span class="k">print</span> <span class="sh">"</span><span class="s">Bot shoudld turn clockwise</span><span class="sh">"</span>
   <span class="n">sock</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="sh">'</span><span class="s">1</span><span class="sh">'</span><span class="p">)</span>
 
<span class="k">elif</span> <span class="n">dX</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">10</span><span class="p">:</span>
   <span class="c1">#'AC' is to turn anti-clockwise
</span>   <span class="k">print</span> <span class="sh">"</span><span class="s">Bot should turn conter-clockwise</span><span class="sh">"</span>
   <span class="n">sock</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="sh">'</span><span class="s">2</span><span class="sh">'</span><span class="p">)</span>
 
 <span class="k">elif</span> <span class="n">dX</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">):</span>
   <span class="c1">#0 is to stop turning
</span>   <span class="k">print</span> <span class="sh">"</span><span class="s">Bot should stop</span><span class="sh">"</span>
   <span class="n">sock</span><span class="p">.</span><span class="nf">send</span><span class="p">(</span><span class="sh">'</span><span class="s">0</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <h1 id="motor-control-and-hardware">Motor Control and Hardware</h1> <p>The hardware part of this project was fairly simple. It involved:</p> <ol> <li>x2 custom circuits(one for the LCD display and the other for the motors)</li> <li>x4 plastic gear-box motors</li> <li>x1 metal chassis bought here</li> <li>x1 Arduino Mega</li> <li>x1 HC-05 bluetooth module</li> <li>x1 LCD dislpay</li> <li>Perf-board for interfacing the Arduino with the LCD display.</li> </ol> <p>The first thing to be set up was the circuit that would be responsible for running four motors in parallel. Generally, one L293D IC can control the direction and speed of two motors. Hence, to be able to run four motors, two L293D IC’s were used together in the configuration shown below. The labels show the digital pins on the Arduino to which the driver’s were connected to.</p> <p><img src="motor_driver.png" alt="Motor Driver Figure"> <em>Pin connections for the drivers</em></p> <p>Once the connections had been made, the Arduino had to be programmed to accept the information received from the HC-05 module via Serial3. Again, the code for this can be seen on the github page mentioned at the top of the page.</p> <p>For the LCD display, I used a perf board to wire out the circuit shown over here. This is pretty much standard for the Arduino. Using this alongside the LiquidCrystal library available for the Arduino IDE, the LCD display was set up to display the direction that the bot is meant to turn to return to the mean position.</p> <h1 id="final-thoughts">Final Thoughts</h1> <p>The bot works surprisingly well given that it was slapped together kinda haphazardly. To be completely honest, the motors that I’ve used for this project are pretty bad and don’t offer enough torque for turning slowly. This makes things kinda messy when you move the object around in the bots field of view too quickly. Additionally, the way the bot corrects its positions is kinda janky at the moment.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2018/Segmentation-Of-Heartbeat-Sounds-Using-Shannon-Energy-Envelopes/">Segmentation Of Heartbeat Sounds Using Shannon Energy Envelopes</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Spring-System/">Simulating Fabrics: A Spring Element Approach</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Adithya Narayan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>